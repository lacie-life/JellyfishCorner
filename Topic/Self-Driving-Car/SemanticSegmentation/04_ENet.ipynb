{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENET FOR IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imutils==0.5.2\n",
      "  Downloading imutils-0.5.2.tar.gz (15 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting numpy==1.16.4\n",
      "  Downloading numpy-1.16.4-cp37-cp37m-manylinux1_x86_64.whl (17.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting opencv-python==4.1.0.25\n",
      "  Downloading opencv_python-4.1.0.25-cp37-cp37m-manylinux1_x86_64.whl (26.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.6/26.6 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: imutils\n",
      "  Building wheel for imutils (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for imutils: filename=imutils-0.5.2-py3-none-any.whl size=24395 sha256=f113afa20a2cbc963ea0f648fcb94e73fd311707fa5adcbca4d5952d1a532e1c\n",
      "  Stored in directory: /home/lacie/.cache/pip/wheels/f6/44/75/ea7a0912ee008afb11b987967a55c9669fbd2a1d5e62ba7a41\n",
      "Successfully built imutils\n",
      "Installing collected packages: imutils, numpy, opencv-python\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.6\n",
      "    Uninstalling numpy-1.21.6:\n",
      "      Successfully uninstalled numpy-1.21.6\n",
      "  Attempting uninstall: opencv-python\n",
      "    Found existing installation: opencv-python 4.8.0.74\n",
      "    Uninstalling opencv-python-4.8.0.74:\n",
      "      Successfully uninstalled opencv-python-4.8.0.74\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "seaborn 0.12.2 requires numpy!=1.24.0,>=1.17, but you have numpy 1.16.4 which is incompatible.\n",
      "scipy 1.7.3 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.16.4 which is incompatible.\n",
      "pandas 1.3.5 requires numpy>=1.17.3; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\", but you have numpy 1.16.4 which is incompatible.\n",
      "matplotlib 3.5.3 requires numpy>=1.17, but you have numpy 1.16.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed imutils-0.5.2 numpy-1.16.4 opencv-python-4.1.0.25\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "SET_WIDTH = int(600)\n",
    "\n",
    "normalize_image = 1 / 255.0\n",
    "resize_image_shape = (1024, 512)\n",
    "\n",
    "sample_img = cv2.imread('../Data/images/example_02.jpg')\n",
    "sample_img = imutils.resize(sample_img, width=SET_WIDTH)\n",
    "\n",
    "blob_img = cv2.dnn.blobFromImage(sample_img, normalize_image, resize_image_shape, 0,swapRB=True, crop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading model...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading model...\")\n",
    "cv_enet_model = cv2.dnn.readNet('../Data/enet-cityscapes/enet-model.net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_enet_model.setInput(blob_img)\n",
    "\n",
    "cv_enet_model_output = cv_enet_model.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_values = open('../Data/enet-cityscapes/enet-classes.txt').read().strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_OUTPUT_SHAPE_START =1\n",
    "IMG_OUTPUT_SHAPE_END =4\n",
    "(classes_num, h, w) = cv_enet_model_output.shape[IMG_OUTPUT_SHAPE_START:IMG_OUTPUT_SHAPE_END]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = np.argmax(cv_enet_model_output[0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.path.isfile('../Data/enet-cityscapes/enet-colors.txt'):\n",
    "    CV_ENET_SHAPE_IMG_COLORS = open('../Data/enet-cityscapes/enet-colors.txt').read().strip().split(\"\\n\")\n",
    "    CV_ENET_SHAPE_IMG_COLORS = [np.array(c.split(\",\")).astype(\"int\") for c in CV_ENET_SHAPE_IMG_COLORS]\n",
    "    CV_ENET_SHAPE_IMG_COLORS = np.array(CV_ENET_SHAPE_IMG_COLORS, dtype=\"uint8\")\n",
    "\n",
    "else:\n",
    "   \n",
    "    np.random.seed(42)\n",
    "    CV_ENET_SHAPE_IMG_COLORS = np.random.randint(0, 255, size=(len(label_values) - 1, 3),\n",
    "                               dtype=\"uint8\")\n",
    "    CV_ENET_SHAPE_IMG_COLORS = np.vstack([[0, 0, 0], CV_ENET_SHAPE_IMG_COLORS]).astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_class_map = CV_ENET_SHAPE_IMG_COLORS[class_map]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_class_map = cv2.resize(mask_class_map, (sample_img.shape[1], sample_img.shape[0]),\n",
    "                  interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "class_map = cv2.resize(mask_class_map, (sample_img.shape[1], sample_img.shape[0]),\n",
    "                      interpolation=cv2.INTER_NEAREST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_enet_model_output = ((0.4 * sample_img) + (0.6 * mask_class_map)).astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_legend = np.zeros(((len(label_values) * 25) + 25, 300, 3), dtype=\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i, (class_name, img_color)) in enumerate(zip(label_values, CV_ENET_SHAPE_IMG_COLORS)):\n",
    "    # draw the class name + color on the legend\n",
    "    color_info = [int(color) for color in img_color]\n",
    "    cv2.putText(my_legend, class_name, (5, (i * 25) + 17),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "    cv2.rectangle(my_legend, (100, (i * 25)), (300, (i * 25) + 25),\n",
    "                  tuple(color_info), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"My_Legend\", my_legend)\n",
    "cv2.imshow(\"Img_Input\", sample_img)\n",
    "cv2.imshow(\"CV_Model_Output\", cv_enet_model_output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "end = time.time()\n",
    "print(\"[INFO] inference took {:.4f} seconds\".format(end - start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENET FOR VIDEOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import imutils\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "DEFAULT_FRAME = 1\n",
    "SET_WIDTH = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = open('../Data/enet-cityscapes/enet-classes.txt').read().strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('../Data/enet-cityscapes/enet-colors.txt'):\n",
    "    CV_ENET_SHAPE_IMG_COLORS = open('../Data/enet-cityscapes/enet-colors.txt').read().strip().split(\"\\n\")\n",
    "    CV_ENET_SHAPE_IMG_COLORS = [np.array(c.split(\",\")).astype(\"int\") for c in CV_ENET_SHAPE_IMG_COLORS]\n",
    "    CV_ENET_SHAPE_IMG_COLORS = np.array(CV_ENET_SHAPE_IMG_COLORS, dtype=\"uint8\")\n",
    "\n",
    "else:\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    CV_ENET_SHAPE_IMG_COLORS = np.random.randint(0, 255, size=(len(class_labels) - 1, 3),\n",
    "                               dtype=\"uint8\")\n",
    "    CV_ENET_SHAPE_IMG_COLORS = np.vstack([[0, 0, 0], CV_ENET_SHAPE_IMG_COLORS]).astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading model...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading model...\")\n",
    "cv_enet_model = cv2.dnn.readNet('../Data/enet-cityscapes/enet-model.net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv = cv2.VideoCapture('../Data/video//video.mp4')\n",
    "sample_video_writer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<VideoCapture 0x7f364299f470>\n"
     ]
    }
   ],
   "source": [
    "print(sv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop = cv2.cv.CV_CAP_PROP_FRAME_COUNT if imutils.is_cv2() \\\n",
    "        else cv2.CAP_PROP_FRAME_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = int(sv.get(prop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1007"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 1007 total frames in video\n",
      "sample_video_writer is None\n",
      "[INFO] single video_frame took 0.3064 seconds\n",
      "[INFO] estimated total_time time: 308.5439\n",
      "[INFO] cleaning up...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# try to determine the total number of frames in the video file\n",
    "try:\n",
    "    prop = cv2.cv.CV_CAP_PROP_FRAME_COUNT if imutils.is_cv2() \\\n",
    "        else cv2.CAP_PROP_FRAME_COUNT\n",
    "    total = int(sv.get(prop))\n",
    "    print(\"[INFO] {} total frames in video\".format(total))\n",
    "\n",
    "# an error occurred while trying to determine the total\n",
    "# number of frames in the video file\n",
    "except:\n",
    "    print(\"[INFO] could not determine # of frames in video\")\n",
    "    total = -1\n",
    "#sample_video\n",
    "# loop over frames from the video file stream\n",
    "while True:\n",
    "    # read the next frame from the file\n",
    "    (grabbed, frame) = sv.read()\n",
    "\n",
    "    # if the frame was not grabbed, then we have reached the end\n",
    "    # of the stream\n",
    "    if not grabbed:\n",
    "        break\n",
    "\n",
    "    # construct a blob from the frame and perform a forward pass\n",
    "    # using the segmentation model\n",
    "    normalize_image = 1 / 255.0\n",
    "    resize_image_shape = (1024, 512)\n",
    "    video_frame = imutils.resize(frame, width=SET_WIDTH)\n",
    "    blob_img = cv2.dnn.blobFromImage(frame,  normalize_image,resize_image_shape, 0,\n",
    "                                 swapRB=True, crop=False)\n",
    "    cv_enet_model.setInput(blob_img)\n",
    "    start = time.time()\n",
    "    cv_enet_model_output = cv_enet_model.forward()\n",
    "    end = time.time()\n",
    "\n",
    "    # infer the total number of classes along with the spatial\n",
    "    # dimensions of the mask image via the shape of the output array\n",
    "    (Classes_num, height, width) = cv_enet_model_output.shape[1:4]\n",
    "\n",
    "    # our output class ID map will be num_classes x height x width in\n",
    "    # size, so we take the argmax to find the class label with the\n",
    "    # largest probability for each and every (x, y)-coordinate in the\n",
    "    # image\n",
    "    classMap = np.argmax(cv_enet_model_output[0], axis=0)\n",
    "\n",
    "    # given the class ID map, we can map each of the class IDs to its\n",
    "    # corresponding color\n",
    "    \n",
    "    mask_class_map = CV_ENET_SHAPE_IMG_COLORS[classMap]\n",
    "\n",
    "    # resize the mask such that its dimensions match the original size\n",
    "    # of the input frame\n",
    "    \n",
    "    \n",
    "    mask_class_map = cv2.resize(mask_class_map, (video_frame.shape[1], video_frame.shape[0]),\n",
    "                      interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    # perform a weighted combination of the input frame with the mask\n",
    "    # to form an output visualization\n",
    "    \n",
    "    \n",
    "    cv_enet_model_output = ((0.3 * video_frame) + (0.7 * mask_class_map)).astype(\"uint8\")\n",
    "\n",
    "    # check if the video writer is None\n",
    "    if sample_video_writer is None:\n",
    "        print(\"sample_video_writer is None\")\n",
    "        # initialize our video writer\n",
    "        fourcc_obj = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "\n",
    "        sample_video_writer = cv2.VideoWriter('./output/output_toronoto.avi', fourcc_obj, 30,\n",
    "                                 (cv_enet_model_output.shape[1], cv_enet_model_output.shape[0]), True)\n",
    "\n",
    "        # some information on processing single frame\n",
    "        if total > 0:\n",
    "            \n",
    "            execution_time = (end - start)\n",
    "            print(\"[INFO] single video_frame took {:.4f} seconds\".format(execution_time))\n",
    "\n",
    "            print(\"[INFO] estimated total_time time: {:.4f}\".format(\n",
    "                execution_time * total))\n",
    "\n",
    "    # write the output frame to disk\n",
    "    \n",
    "    sample_video_writer.write(cv_enet_model_output)\n",
    "\n",
    "    # check to see if we should display the output frame to our screen\n",
    "    if DEFAULT_FRAME > 0:\n",
    "        cv2.imshow(\"Video Frame\", cv_enet_model_output)\n",
    "        \n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        \n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "print(\"[INFO] cleaning up...\")\n",
    "sample_video_writer.release()\n",
    "sv.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
